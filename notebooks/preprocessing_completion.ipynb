{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing completion\n",
    "\n",
    "Notebook pour compléter les vidéos dont le preprocessing a échoué pour une raison ou une autre..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import dfdetect.utils as utils\n",
    "import numpy as np\n",
    "from dfdetect.data_loaders import DFDC, DFDC_preprocessed_single_frames\n",
    "from tqdm.auto import tqdm\n",
    "import dfdetect.preprocessing.face_detection as fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_path = os.environ.get(\"DFDC_DATASET_PATH\", \"./dfdc_test_set\")\n",
    "new_path = os.environ.get(\n",
    "    \"DFDC_PREPROCESSED_DATASET_PATH\",\n",
    "    \"./dfdc_preprocessed_frames_test\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0x1B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DFDC(old_path, is_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = DFDC_preprocessed_single_frames(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdc_ids = set(dataset.desc[\"index\"])\n",
    "preprocessed_dfdc_ids = set(preprocessed_dataset.desc[\"dfdc_id\"])\n",
    "missing = list(dfdc_ids - preprocessed_dfdc_ids)\n",
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fname = os.path.join(new_path, \"labels.csv\")\n",
    "target_ratio = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fd_waterfall(frame):\n",
    "    (bboxes,) = fd.detect_face_blazeface([frame])\n",
    "    if len(bboxes) == 0:\n",
    "        (bboxes,) = fd.detect_face_mtcnn([frame])\n",
    "    if len(bboxes) == 0:\n",
    "        (bboxes,) = fd.detect_face_retinaface([frame])\n",
    "    return bboxes\n",
    "\n",
    "\n",
    "def preprocessing_function(index, is_test=True):\n",
    "    meta = dataset.desc.iloc[index]\n",
    "    output_frames = []\n",
    "    error_loading = True\n",
    "    if meta[\"label\"] == \"FAKE\" and not is_test:\n",
    "        \"\"\"In training, we use the original video to filter our fake faces from real faces in fake videos\"\"\"\n",
    "        original_name = meta[\"original\"]\n",
    "        original_path = os.path.join(os.path.dirname(meta[\"path\"]), original_name)\n",
    "        real_frames = utils.video_to_frames(original_path)[0]\n",
    "        fake_frames = utils.video_to_frames(meta[\"path\"])[0]\n",
    "        for real_frame, fake_frame in zip(real_frames, fake_frames):\n",
    "            error_loading = False\n",
    "            bboxes = fd_waterfall(real_frame)\n",
    "            for bbox in bboxes:\n",
    "                bbox.recast()\n",
    "                if bbox.width() * bbox.height() == 0:\n",
    "                    continue\n",
    "                real_face, fake_face = list(\n",
    "                    utils.crop_frames([real_frame, fake_frame], [bbox, bbox])\n",
    "                )\n",
    "                change_ratio = np.count_nonzero(real_face - fake_face) / np.product(\n",
    "                    real_face.shape\n",
    "                )\n",
    "                if change_ratio > target_ratio:\n",
    "                    output_frames.append(fake_face)\n",
    "            if len(output_frames) > 0:\n",
    "                break\n",
    "    else:  # REAL or testing\n",
    "        real_frames = utils.video_to_frames(meta[\"path\"])[0]\n",
    "        for real_frame in real_frames:\n",
    "            error_loading = False\n",
    "            bboxes = fd_waterfall(real_frame)\n",
    "            for n in range(len(bboxes)):\n",
    "                bbox = bboxes[n]\n",
    "                bbox.recast()\n",
    "                if bbox.width() * bbox.height() == 0:\n",
    "                    del bboxes[n]\n",
    "            real_faces = list(utils.crop_frames([real_frame] * len(bboxes), bboxes))\n",
    "            if len(real_faces) > 0:\n",
    "                if is_test:  # Keep only 1 image per video in test\n",
    "                    output_frames.append(real_faces[0])\n",
    "                else:\n",
    "                    output_frames += real_faces\n",
    "                break\n",
    "\n",
    "    if error_loading:\n",
    "        print(\"Error while loading video:\", meta[\"path\"], meta[\"label\"])\n",
    "        return\n",
    "\n",
    "    if len(output_frames) == 0:\n",
    "        print(\"Error while processing video:\", meta[\"path\"])\n",
    "    else:\n",
    "        video_original_name = dataset.get_filename(index)\n",
    "        _, file_extension = os.path.splitext(video_original_name)\n",
    "        image_path = os.path.join(\n",
    "            new_path, video_original_name.replace(file_extension, \".png\")\n",
    "        )\n",
    "\n",
    "        for i in range(len(output_frames)):\n",
    "            try:\n",
    "                c_path = image_path.replace(\".png\", f\"_{i}.png\")\n",
    "                cv2.imwrite(c_path, cv2.cvtColor(output_frames[i], cv2.COLOR_RGB2BGR))\n",
    "\n",
    "                with io.open(metadata_fname, \"a\") as f:\n",
    "                    f.write(f\"{video_original_name},{c_path},{meta['label']}\\n\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(\"Error while saving for video:\", meta[\"path\"])\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_empty(index, is_test=True):\n",
    "    \"\"\"Preprocess test frame by cropping a 100x100 block in the middle for the frames where face is undetectable\"\"\"\n",
    "    meta = dataset.desc.iloc[index]\n",
    "    video_original_name = dataset.get_filename(index)\n",
    "    _, file_extension = os.path.splitext(video_original_name)\n",
    "    image_path = os.path.join(\n",
    "        new_path, video_original_name.replace(file_extension, \"_0.png\")\n",
    "    )\n",
    "    frames = list(utils.video_to_frames(meta[\"path\"])[0])\n",
    "    if len(frames) == 0:\n",
    "        print(\"Error while loading video:\", meta[\"path\"], meta[\"label\"])\n",
    "        return\n",
    "    mid_frame = len(frames) // 2\n",
    "    frame = frames[mid_frame]\n",
    "    h, w, c = frame.shape\n",
    "    sh, sw = h // 2 - 50, w // 2 - 50\n",
    "    face = frame[sh : sh + 100, sw : sw + 100, :]\n",
    "    cv2.imwrite(image_path, cv2.cvtColor(face, cv2.COLOR_RGB2BGR))\n",
    "    with io.open(metadata_fname, \"a\") as f:\n",
    "        f.write(f\"{video_original_name},{image_path},{meta['label']}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id_name in tqdm(missing):\n",
    "    (position,) = np.where(dataset.desc[\"index\"] == id_name)\n",
    "    preprocessing_empty(position[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dataset = DFDC_preprocessed_single_frames(new_path)\n",
    "preprocessed_dfdc_ids = set(preprocessed_dataset.desc[\"dfdc_id\"])\n",
    "missing = list(dfdc_ids - preprocessed_dfdc_ids)\n",
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "local-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
